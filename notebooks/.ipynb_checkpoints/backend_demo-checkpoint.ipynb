{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Funtioning Backend Demo\n",
    "\n",
    "This notebook is designed to show how the DSEM pipeline works. It's fully funtioning, using SEM and RL NAS. Please fasten your seat belt and enjoy the journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import autogluon as ag\n",
    "import rpy2.robjects as ro\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from SEM import SemModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data\n",
    "\n",
    "In this demo, we use dataset _PoliticalDemocracy_ from Bollen's book on structural equation modeling published in 1989. We load this dataset in R and convert it to Python Dataframe for further usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.464667</td>\n",
       "      <td>4.256443</td>\n",
       "      <td>6.563110</td>\n",
       "      <td>4.452533</td>\n",
       "      <td>5.136252</td>\n",
       "      <td>2.978074</td>\n",
       "      <td>6.196264</td>\n",
       "      <td>4.043390</td>\n",
       "      <td>5.054384</td>\n",
       "      <td>4.792195</td>\n",
       "      <td>3.557690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.622702</td>\n",
       "      <td>3.947128</td>\n",
       "      <td>3.280891</td>\n",
       "      <td>3.349467</td>\n",
       "      <td>2.612602</td>\n",
       "      <td>3.372733</td>\n",
       "      <td>3.286240</td>\n",
       "      <td>3.245593</td>\n",
       "      <td>0.732904</td>\n",
       "      <td>1.510664</td>\n",
       "      <td>1.405711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>1.581500</td>\n",
       "      <td>3.691701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.477661</td>\n",
       "      <td>1.300916</td>\n",
       "      <td>4.477337</td>\n",
       "      <td>3.663233</td>\n",
       "      <td>2.300181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.400000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.075174</td>\n",
       "      <td>4.962845</td>\n",
       "      <td>3.568079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>8.283332</td>\n",
       "      <td>9.999998</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>4.206853</td>\n",
       "      <td>9.999998</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>5.515424</td>\n",
       "      <td>5.830362</td>\n",
       "      <td>4.522988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.999998</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.999998</td>\n",
       "      <td>9.999998</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.736967</td>\n",
       "      <td>7.872074</td>\n",
       "      <td>6.424591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              y1         y2         y3         y4         y5         y6  \\\n",
       "count  75.000000  75.000000  75.000000  75.000000  75.000000  75.000000   \n",
       "mean    5.464667   4.256443   6.563110   4.452533   5.136252   2.978074   \n",
       "std     2.622702   3.947128   3.280891   3.349467   2.612602   3.372733   \n",
       "min     1.250000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     2.900000   0.000000   3.766667   1.581500   3.691701   0.000000   \n",
       "50%     5.400000   3.333333   6.666666   3.333333   5.000000   2.233333   \n",
       "75%     7.500000   8.283332   9.999998   6.666666   7.500000   4.206853   \n",
       "max    10.000000   9.999998  10.000000  10.000000  10.000000   9.999998   \n",
       "\n",
       "              y7         y8         x1         x2         x3  \n",
       "count  75.000000  75.000000  75.000000  75.000000  75.000000  \n",
       "mean    6.196264   4.043390   5.054384   4.792195   3.557690  \n",
       "std     3.286240   3.245593   0.732904   1.510664   1.405711  \n",
       "min     0.000000   0.000000   3.784190   1.386294   1.001674  \n",
       "25%     3.477661   1.300916   4.477337   3.663233   2.300181  \n",
       "50%     6.666666   3.333333   5.075174   4.962845   3.568079  \n",
       "75%     9.999998   6.666666   5.515424   5.830362   4.522988  \n",
       "max     9.999998  10.000000   6.736967   7.872074   6.424591  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load this dataset in R.\n",
    "ro.packages.importr('lavaan')\n",
    "rData = ro.r('PoliticalDemocracy')\n",
    "\n",
    "# Convert it to Python Dataframe.\n",
    "with ro.conversion.localconverter(ro.default_converter + ro.pandas2ri.converter):\n",
    "    data = ro.conversion.rpy2py(rData)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conventional SEM\n",
    "\n",
    "After loading this dataset, let's play with the conventional SEM. It is a truth universally acknowledged, that SEM is rather confirmative than explorative. So the very only way to play with the conventional SEM is to run SEM on a manually proposed model.\n",
    "\n",
    "Therefore, we use the model from lavaan (a package in R) official tutorial as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGFI: 0.765110 \n",
      "RMSEA: 0.101150\n"
     ]
    }
   ],
   "source": [
    "# Describe the model\n",
    "model = '''\n",
    "  # measurement model\n",
    "    ind60 =~ x1 + x2 + x3\n",
    "    dem60 =~ y1 + y2 + y3 + y4\n",
    "    dem65 =~ y5 + y6 + y7 + y8\n",
    "  # regressions\n",
    "    dem60 ~ ind60\n",
    "    dem65 ~ ind60 + dem60\n",
    "'''\n",
    "\n",
    "# Create the model and fit the data.\n",
    "sem = SemModel()\n",
    "buildRes = sem.build_sem_model(model)\n",
    "assert buildRes\n",
    "fitRes = sem.fit_sem_model(data)\n",
    "assert fitRes['is_fitted']\n",
    "\n",
    "# Evaluate the model fitted.\n",
    "measureRes = sem.evaluate_sem_model()\n",
    "print('AGFI: %f \\nRMSEA: %f' % (\n",
    "    measureRes['agfi'], \n",
    "    measureRes['rmsea']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep SEM\n",
    "\n",
    "Now let's try to apply RL NAS technology to SEM. In this section, we define the search space first, and then the search strategy, finally let's combine everything together.\n",
    "\n",
    "Firstly, let's start with search space.\n",
    "\n",
    "### 3.1. Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "facNames = ['factor1', 'factor2', 'factor3']  # Use the same factor number as the model propsoed above.\n",
    "facNum = len(facNames)\n",
    "varNames = data.columns\n",
    "varNum = len(varNames)\n",
    "\n",
    "# Define the search space.\n",
    "searchSpace = {var: ag.space.Categorical(*facNames) \n",
    "               for var in varNames}  # Define search space for measurement model\n",
    "for i in range(facNum):  # Define search space for regressions model\n",
    "    for j in range(i):\n",
    "        searchSpace[str((facNames[i], facNames[j]))] = ag.space.Categorical(*list(range(4)))\n",
    "\n",
    "def evaluateSolution(model):\n",
    "    try:\n",
    "        sem = SemModel()\n",
    "\n",
    "        buildRes = sem.build_sem_model(model)\n",
    "        if not buildRes:\n",
    "            return 0\n",
    "\n",
    "        fitRes = sem.fit_sem_model(data)\n",
    "        if not fitRes['is_fitted']:\n",
    "            return 0\n",
    "\n",
    "        measureRes = sem.evaluate_sem_model()\n",
    "        if not measureRes['is_evaluated']:\n",
    "            return 0\n",
    "\n",
    "        AGFI = measureRes['agfi']\n",
    "        RMSEA = measureRes['rmsea']\n",
    "        index = AGFI - RMSEA * 10\n",
    "        sigmoidIndex = 1/(1 + np.exp(-index)) \n",
    "        return sigmoidIndex\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def dict2des(dataDict, seperator):\n",
    "    dataDes = ''\n",
    "    for parent in dataDict.keys():\n",
    "        if not dataDict[parent]:\n",
    "            continue;\n",
    "        \n",
    "        relaDes = '' \n",
    "        for son in dataDict[parent]:\n",
    "            if not relaDes:\n",
    "                relaDes += son\n",
    "            else:\n",
    "                relaDes += ' + ' + son\n",
    "                \n",
    "        dataDes += parent + ' ' + seperator + ' ' + relaDes + '\\n'\n",
    "       \n",
    "    return dataDes\n",
    "    \n",
    "@ag.args(**searchSpace)\n",
    "def rl_simulation(args, reporter):\n",
    "    measurementDict = {fac: [] for fac in facNames}\n",
    "    regressionsDict = {fac: [] for fac in facNames} \n",
    "    facNum = len(facNames)\n",
    "    edge_cnt = 0\n",
    "    \n",
    "    for var, choice in args.items():\n",
    "        if var == 'task_id': \n",
    "            continue\n",
    "        elif var[0] != '(':  # measurement\n",
    "            measurementDict[choice].append(var)\n",
    "        else:  # regressions\n",
    "            varTuple = eval(var)\n",
    "            if choice == 1:\n",
    "                regressionsDict[varTuple[0]].append(varTuple[1])\n",
    "            elif choice == 2:\n",
    "                regressionsDict[varTuple[1]].append(varTuple[0])\n",
    "            elif choice == 3:\n",
    "                regressionsDict[varTuple[0]].append(varTuple[1])\n",
    "                regressionsDict[varTuple[1]].append(varTuple[0])\n",
    "            if choice > 0:\n",
    "                edge_cnt = edge_cnt + 1\n",
    "    \n",
    "    if (edge_cnt > math.ceil(facNum * math.log(facNum, 2))):\n",
    "        reporter(reward=0)\n",
    "        return\n",
    "\n",
    "    # Prior knowledge from SEM.\n",
    "    for fac, ind in measurementDict.items():\n",
    "        if (len(ind) < 2):\n",
    "            reporter(reward=0)\n",
    "            return\n",
    "    \n",
    "    modelDes = dict2des(measurementDict, '=~') + \\\n",
    "               dict2des(regressionsDict, '~')\n",
    "    \n",
    "    reward = evaluateSolution(modelDes)\n",
    "    \n",
    "    reporter(reward=reward)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Search Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scheduler_options: Key 'resume': Imputing default value False\n",
      "scheduler_options: Key 'checkpoint': Imputing default value ./exp/checkpoint.ag\n",
      "scheduler_options: Key 'ema_baseline_decay': Imputing default value 0.95\n",
      "scheduler_options: Key 'controller_resource': Imputing default value {'num_cpus': 0, 'num_gpus': 0}\n",
      "scheduler_options: Key 'sync': Imputing default value True\n",
      "\n",
      "scheduler_options: Key 'time_attr': Imputing default value epoch\n",
      "scheduler_options: Key 'visualizer': Imputing default value none\n",
      "scheduler_options: Key 'training_history_callback_delta_secs': Imputing default value 60\n",
      "scheduler_options: Key 'delay_get_config': Imputing default value True\n",
      "\n",
      "Reserved DistributedResource(\n",
      "\tNode = Remote REMOTE_ID: 0, \n",
      "\t<Remote: 'inproc://172.20.10.2/502/1' processes=1 threads=8, memory=16.53 GB>\n",
      "\tnCPUs = 0) in Remote REMOTE_ID: 0, \n",
      "\t<Remote: 'inproc://172.20.10.2/502/1' processes=1 threads=8, memory=16.53 GB>\n",
      "Starting Experiments\n",
      "Num of Finished Tasks is 0\n",
      "Num of Pending Tasks is 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b68eeccec98421eb9958f84087b2ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=51), HTML(value=''))), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in lav_fit_measures(object = object, fit.measures = fit.measures,  : \n",
      "  lavaan ERROR: fit measures not available if model did not converge\n",
      "\n",
      "R[write to console]: In addition: \n",
      "R[write to console]: Warning messages:\n",
      "\n",
      "R[write to console]: 1: \n",
      "R[write to console]: In lav_model_estimate(lavmodel = lavmodel, lavpartable = lavpartable,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  lavaan WARNING: the optimizer warns that a solution has NOT been found!\n",
      "\n",
      "R[write to console]: 2: \n",
      "R[write to console]: In lav_model_estimate(lavmodel = lavmodel, lavpartable = lavpartable,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  lavaan WARNING: the optimizer warns that a solution has NOT been found!\n",
      "\n",
      "R[write to console]: 3: \n",
      "R[write to console]: In lav_model_estimate(lavmodel = lavmodel, lavpartable = lavpartable,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  lavaan WARNING: the optimizer (NLMINB) claimed the model converged,\n",
      "                  but not all elements of the gradient are (near) zero;\n",
      "                  the optimizer may not have found a local solution\n",
      "                  use check.gradient = FALSE to skip this check.\n",
      "\n",
      "R[write to console]: 4: \n",
      "R[write to console]: In lav_model_estimate(lavmodel = lavmodel, lavpartable = lavpartable,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  lavaan WARNING: the optimizer (NLMINB) claimed the model converged,\n",
      "                  but not all elements of the gradient are (near) zero;\n",
      "                  the optimizer may not have found a local solution\n",
      "                  use check.gradient = FALSE to skip this check.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluate_sem_model function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Fatal error: unable to initialize the JIT\n",
      "\n",
      "\n",
      "R[write to console]: Error in lav_fit_measures(object = object, fit.measures = fit.measures,  : \n",
      "  lavaan ERROR: fit measures not available if model did not converge\n",
      "\n",
      "R[write to console]: In addition: \n",
      "R[write to console]: Warning messages:\n",
      "\n",
      "R[write to console]: 1: \n",
      "R[write to console]: In lav_model_estimate(lavmodel = lavmodel, lavpartable = lavpartable,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  lavaan WARNING: the optimizer warns that a solution has NOT been found!\n",
      "\n",
      "R[write to console]: 2: \n",
      "R[write to console]: In lav_model_estimate(lavmodel = lavmodel, lavpartable = lavpartable,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  lavaan WARNING: the optimizer warns that a solution has NOT been found!\n",
      "\n",
      "R[write to console]: 3: \n",
      "R[write to console]: In lav_model_estimate(lavmodel = lavmodel, lavpartable = lavpartable,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  lavaan WARNING: the optimizer warns that a solution has NOT been found!\n",
      "\n",
      "R[write to console]: 4: \n",
      "R[write to console]: In lav_model_estimate(lavmodel = lavmodel, lavpartable = lavpartable,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  lavaan WARNING: the optimizer warns that a solution has NOT been found!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluate_sem_model function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Fatal error: unable to initialize the JIT\n",
      "\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Fatal error: unable to initialize the JIT\n",
      "\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Fatal error: unable to initialize the JIT\n",
      "\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Fatal error: unable to initialize the JIT\n",
      "\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Fatal error: unable to initialize the JIT\n",
      "\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Fatal error: unable to initialize the JIT\n",
      "\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Fatal error: unable to initialize the JIT\n",
      "\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Fatal error: unable to initialize the JIT\n",
      "\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Fatal error: unable to initialize the JIT\n",
      "\n",
      "\n",
      "R[write to console]: Error: ignoring SIGPIPE signal\n",
      "\n",
      "R[write to console]: Fatal error: unable to initialize the JIT\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best config: {'y1.choice': 0, 'y2.choice': 1, 'y3.choice': 1, 'y4.choice': 1, 'y5.choice': 0, 'y6.choice': 0, 'y7.choice': 1, 'y8.choice': 2, 'x1.choice': 2, 'x2.choice': 2, 'x3.choice': 2, \"('factor2', 'factor1').choice\": 1, \"('factor3', 'factor1').choice\": 0, \"('factor3', 'factor2').choice\": 1}, best reward: 0.2589677019122003\n"
     ]
    }
   ],
   "source": [
    "# Running the following code might crash Python.\n",
    "# This problem is caused by the multiprocessing of the RL algorithm and lavaan in R.\n",
    "# But the numeric part has been take care of, so the result is not currupted.\n",
    "rl_scheduler = ag.scheduler.RLScheduler(rl_simulation,\n",
    "                                        resource={'num_cpus': 1, 'num_gpus': 0},\n",
    "                                        num_trials=200,\n",
    "                                        reward_attr='reward',\n",
    "                                        controller_batch_size=4,\n",
    "                                        controller_lr=5e-3,)\n",
    "\n",
    "rl_scheduler.run()\n",
    "rl_scheduler.join_jobs()\n",
    "    \n",
    "print('Best config: {}, best reward: {}'.format(rl_scheduler.get_best_config(), rl_scheduler.get_best_reward()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0a846fc240>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "curveRL = [v[0]['reward'] for v in rl_scheduler.training_history.values()]\n",
    "curveSmooth = [np.max(curveRL[i:i+5]) for i in range(0, len(curveRL), 5)]\n",
    "\n",
    "plt.plot(range(len(curveSmooth)), curveSmooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison\n",
    "\n",
    "Now let's compare those conventional SEM and DSEM. First let's started with conventional SEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4387111083947727"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = '''\n",
    "  # measurement model\n",
    "    ind60 =~ x1 + x2 + x3\n",
    "    dem60 =~ y1 + y2 + y3 + y4\n",
    "    dem65 =~ y5 + y6 + y7 + y8\n",
    "  # regressions\n",
    "    dem60 ~ ind60\n",
    "    dem65 ~ ind60 + dem60\n",
    "'''\n",
    "\n",
    "evaluateSolution(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move to DSEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'choice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4c876419e4ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmeasurementDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfacNames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# regressions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mvarTuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mregressionsDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvarTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvarTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'choice'"
     ]
    }
   ],
   "source": [
    "args = rl_scheduler.get_best_config()\n",
    "\n",
    "measurementDict = {fac: [] for fac in facNames}\n",
    "regressionsDict = {fac: [] for fac in facNames} \n",
    "        \n",
    "for var, choice in args.items():\n",
    "    var = var.split('‚ñÅ')[0]\n",
    "    if var[0] != '(':  # measurement\n",
    "        measurementDict[facNames[choice]].append(var)\n",
    "    else:  # regressions\n",
    "        varTuple = eval(var)\n",
    "        if choice == 1:\n",
    "            regressionsDict[varTuple[0]].append(varTuple[1])\n",
    "        elif choice == 2:\n",
    "            regressionsDict[varTuple[1]].append(varTuple[0])\n",
    "        elif choice == 3:\n",
    "            regressionsDict[varTuple[0]].append(varTuple[1])\n",
    "            regressionsDict[varTuple[1]].append(varTuple[0])\n",
    "\n",
    "modelDes = dict2des(measurementDict, '=~') + \\\n",
    "           dict2des(regressionsDict, '~')\n",
    "\n",
    "print('The best model looks like:\\n' + modelDes)\n",
    "    \n",
    "evaluateSolution(modelDes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
